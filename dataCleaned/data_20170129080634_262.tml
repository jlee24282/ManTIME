<?xml version="1.0" ?>
<TimeML xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://timeml.org/timeMLdocs/TimeML_1.2.1.xsd">
<DOCID>695194080241</DOCID>
<DCT><TIMEX3 tid="t0" type="DATE" value="2017-01-29" temporalFunction="false" functionInDocument="CREATION_TIME">January 29, 2017</TIMEX3></DCT>
<TITLE>No one can read what’s on the cards for AI’s future</TITLE>
<TEXT>
AI is now beating us at poker, but not even Google co-founder Sergey Brin can say with any certainty what the next steps for machine learning are Ten days ago, in a Davos still shellshocked by Trump’s victory, one of the former masters of the universe sat down with an interviewer to talk about artificial intelligence (AI) and the future. His name is Sergey Brin and he is one of the co-founders of Google. The tone of the conversation was thoughtful but subdued, possibly because Brin is not a master in Trump’s universe, but mainly because he’s a smart and thoughtful guy. When asked about the future of AI he replied – sensibly – that it was "impossible to forecast accurately" and followed up with a story from his own experience. Poker requires reasoning and intelligence that have up until now eluded machines. There’s no single optimal move Ten years ago, Brin was running Google’s X lab, the place where they work on projects that have, at best, a 100-1 chance of success. One little project there was called Google Brain, which focused on AI. "To be perfectly honest," Brin said, "I didn’t pay any attention to it at all." Brain was headed by a computer scientist named Jeff Dean who, Brin recalled, "would periodically come up to me and say, ‘Look – the computer made a picture of a cat!’ and I would say, ‘OK, that’s very nice, Jeff – go do your thing, whatever.’ Fast-forward a few years and now Brain probably touches every single one of our main projects – ranging from search to photos to ads… everything we do. This revolution in deep nets has been very profound and definitely surprised me – even though I was right in there. I could, you know, throw paper clips at Jeff."

Fast-forward a week from that interview and cut to Pittsburgh, where four leading professional poker players are pitting their wits against an AI program created by two Carnegie Mellon university researchers. They’re playing a particular kind of high-stakes poker called heads-up no-limit Texas hold’em. The program is called Libratus, which is Latin for "balanced". There is, however, nothing balanced about its performance. Just over halfway through the 20-day game, Libratus was $800,000 up on the humans, some of whom were beginning to feel depressed. "I didn’t realise how good it was until today," said one of them, Dong Kim. "I felt like I was playing against someone who was cheating, like it could see my cards. I’m not accusing it of cheating. It was just that good."

The match doesn’t end until tomorrow (you can follow it via the hashtag #brainsvsai) and so we don’t know yet if the computer will win. But even if it doesn’t, another milestone has been passed on the road to artificial intelligence, because the Pittsburgh contest has shown that a machine can play a pretty mean game of poker against real human experts. This is a big deal, because poker requires reasoning and intelligence that have up until now eluded machines. There’s no single optimal move and the machine has to change its tactics to ensure that its opponents find it hard to guess when it’s bluffing. Poker, says Will Knight, a robotics expert, "is fundamentally different from checkers, chess, or Go because an opponent’s hand remains hidden from view during play. In games of ‘imperfect information’, it is enormously complicated to figure out the ideal strategy given every possible approach your opponent may be taking. And no-limit Texas hold’em is especially challenging because an opponent could essentially bet any amount."

The Pittsburgh contest will definitely take its place in a sequence of significant stages in the road to some kind of AI. Earlier ones have included IBM’s 1997 Deep Blue victory over Garry Kasparov in chess, its Watson machine’s and in March 2016. Each of these was, understandably, regarded as a stunning achievement at the time, but in reality they were baby steps on what looks like being a very long journey, despite all the hype about "superintelligence". Garry Kasparov holds his head in his hands at the start of his sixth and final chess match against IBM’s Deep Blue computer, 11 May 1997. Photograph: Stan Honda/AFP/ So how could we make an intelligent assessment about the question put to Brin in Davos? One way favoured by the research community is to distinguish between two types of AI – strong and weak. Strong AI means machines with human-level abilities of perception, natural language, reasoning and motor control. Weak AI means the kind of AI we have now – the stuff that enables Amazon or Netflix to guess what you might want to buy or watch next or that Google uses to ‘autocomplete’ search queries: in other words, machine learning plus big data. So in one sense you could say that the future of AI is already here. Strong AI, on the other hand, seems a long way off. Geoffrey Hinton, one of the real gurus of the field, (he turns 70 this year). But although Brin is only 43, he might not get to see it either.
</TEXT>
</TimeML>
